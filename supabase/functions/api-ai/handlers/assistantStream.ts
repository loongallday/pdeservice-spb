/**
 * AI Assistant Streaming Handler
 * Handles AI chat requests with Server-Sent Events (SSE) streaming
 * Like ChatGPT - text appears word by word
 */

import type { Employee } from '../../_shared/auth.ts';
import { AI_TOOLS_OPENAI, type ToolName } from '../services/toolDefinitions.ts';
import { executeTool } from '../services/toolExecutor.ts';
import {
  compressContext,
  createEntityMemory,
  serializeMemory,
  buildEntityContext,
  updateMemoryFromToolCall,
  type EntityMemory,
  type ConversationSummary,
} from '../services/contextManager.ts';
import {
  getOrCreateSession,
  updateSession,
  sessionToEntityMemory,
  saveMessages,
  type AISession,
} from '../services/sessionService.ts';
import { createServiceClient } from '../../_shared/supabase.ts';

/**
 * Clean and extract UUID prefix from a string
 * Strips brackets, dots, ellipsis, and other non-hex characters
 * Returns the cleaned prefix suitable for ilike query (keeps hyphens)
 */
function extractUUIDPrefix(value: string): string | null {
  // Remove common formatting: brackets, dots, ellipsis, quotes, spaces
  const cleaned = value.replace(/[\[\]"'.\s]/g, '').replace(/\.{2,}/g, '');
  // Extract only valid UUID characters (hex + hyphens)
  const uuidMatch = cleaned.match(/^[0-9a-fA-F-]+/);
  if (!uuidMatch) return null;
  // Remove trailing hyphens but keep internal ones
  const uuidPart = uuidMatch[0].replace(/-+$/, '');
  // Count only hex characters (not hyphens) for minimum length check
  const hexOnly = uuidPart.replace(/-/g, '');
  // Need at least 4 hex chars for a meaningful prefix match
  return hexOnly.length >= 4 ? uuidPart : null;
}

/**
 * Resolve partial UUIDs to full UUIDs
 * Used to fix IDs from entity memory context that are shortened for token efficiency
 * Handles various formats: "a1b2c3d4", "[a1b2c3d4]", "a1b2c3d4...", etc.
 */
async function resolvePartialUUIDs(
  toolArgs: Record<string, unknown>
): Promise<Record<string, unknown>> {
  const supabase = createServiceClient();
  const resolved = { ...toolArgs };

  // Resolve site_id if it's shorter than full UUID (36 chars)
  if (typeof resolved.site_id === 'string' && resolved.site_id.length < 36) {
    const prefix = extractUUIDPrefix(resolved.site_id);
    if (prefix) {
      const { data: site } = await supabase
        .from('main_sites')
        .select('id')
        .ilike('id', `${prefix}%`)
        .limit(1)
        .single();
      if (site) {
        console.log(`[ai-stream] Resolved partial site_id "${resolved.site_id}" -> ${site.id}`);
        resolved.site_id = site.id;
      }
    }
  }

  // Resolve employee_ids if they are partial UUIDs
  if (Array.isArray(resolved.employee_ids)) {
    const resolvedIds: string[] = [];
    for (const empId of resolved.employee_ids) {
      if (typeof empId === 'string' && empId.length < 36) {
        const prefix = extractUUIDPrefix(empId);
        if (prefix) {
          const { data: emp } = await supabase
            .from('main_employees')
            .select('id')
            .ilike('id', `${prefix}%`)
            .limit(1)
            .single();
          if (emp) {
            console.log(`[ai-stream] Resolved partial employee_id "${empId}" -> ${emp.id}`);
            resolvedIds.push(emp.id);
          } else {
            resolvedIds.push(empId);
          }
        } else {
          resolvedIds.push(empId);
        }
      } else {
        resolvedIds.push(empId as string);
      }
    }
    resolved.employee_ids = resolvedIds;
  }

  // Resolve company_id if it's shorter than full UUID
  if (typeof resolved.company_id === 'string' && resolved.company_id.length < 36) {
    const prefix = extractUUIDPrefix(resolved.company_id);
    if (prefix) {
      const { data: company } = await supabase
        .from('main_companies')
        .select('id')
        .ilike('id', `${prefix}%`)
        .limit(1)
        .single();
      if (company) {
        console.log(`[ai-stream] Resolved partial company_id "${resolved.company_id}" -> ${company.id}`);
        resolved.company_id = company.id;
      }
    }
  }

  return resolved;
}
import {
  processFiles,
  buildMessageContent,
  type FileAttachment,
  type ProcessedFile,
} from '../services/fileProcessor.ts';
import {
  routeQuery,
  logRouting,
  detectTone,
  type ModelTier,
  type ToneType,
} from '../services/modelRouter.ts';

const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions';
const MAX_TOOL_ITERATIONS = 5; // Increased for complex multi-step tasks
const RECENT_TURNS_TO_KEEP = 3;

interface AIContext {
  page: { route: string; type: string; title: string };
  user: { id: string; role: string; department: string; permissions: string[] };
  data?: Record<string, unknown>;
  ui?: Record<string, unknown>;
  timestamp: string;
}

interface AIMessage {
  role: 'user' | 'assistant' | 'system' | 'tool';
  content: string | null;
  tool_calls?: ToolCall[];
  tool_call_id?: string;
}

interface ToolCall {
  id: string;
  type: 'function';
  function: { name: string; arguments: string };
}

interface ConfirmedTool {
  name: string;
  arguments: Record<string, unknown>;
}

interface RequestBody {
  query: string;
  context: AIContext;
  conversationHistory?: AIMessage[];
  entityMemory?: string;
  sessionId?: string; // Optional: use database session
  files?: FileAttachment[]; // Optional: file attachments (images, PDF, Excel)
  confirmedTools?: ConfirmedTool[]; // Pre-confirmed tools from user
  skipToolConfirmation?: boolean; // Skip confirmation for this request
}

// Tool pending confirmation
interface PendingTool {
  name: string;
  description: string;
  arguments: Record<string, unknown>;
  schema?: Record<string, unknown>; // Parameter schema for UI
}

// SSE Event types
type SSEEvent =
  | { type: 'session'; sessionId: string }
  | { type: 'model'; tier: string; model: string }
  | { type: 'file_processing'; filename: string; status: 'start' | 'done'; fileType?: string }
  | { type: 'text'; content: string }
  | { type: 'tool_start'; tool: string; description: string }
  | { type: 'tool_end'; tool: string; success: boolean; result?: unknown }
  | { type: 'tool_confirmation'; tools: PendingTool[]; assistantMessage?: string }
  | { type: 'done'; sessionId: string; entityMemory: string; usage: { inputTokens: number; outputTokens: number }; contextStats: { compressionRatio: number; entitiesTracked: number; filesProcessed: number }; awaitingConfirmation?: boolean }
  | { type: 'error'; message: string };

/**
 * POST /api-ai/assistant/stream
 * Ask the AI assistant with streaming response
 */
export async function askAssistantStream(
  req: Request,
  employee: Employee
): Promise<Response> {
  // Validate API key
  if (!OPENAI_API_KEY) {
    return new Response(
      formatSSE({ type: 'error', message: 'AI service not configured' }),
      { status: 500, headers: sseHeaders() }
    );
  }

  // Parse request body
  const body: RequestBody = await req.json();
  const {
    query,
    context,
    conversationHistory = [],
    entityMemory: entityMemoryJson,
    sessionId: requestSessionId,
    files = [],
    confirmedTools,
    skipToolConfirmation = false,
  } = body;

  if (!query?.trim()) {
    return new Response(
      formatSSE({ type: 'error', message: '‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°' }),
      { status: 400, headers: sseHeaders() }
    );
  }

  // Process file attachments
  let processedFiles: ProcessedFile[] = [];
  if (files.length > 0) {
    console.log(`[ai-stream] Processing ${files.length} file(s)...`);
    processedFiles = await processFiles(files);
    console.log(`[ai-stream] Processed ${processedFiles.length} file(s): ${processedFiles.map(f => f.type).join(', ')}`);
  }

  // Load or create session from database
  let session: AISession | null = null;
  let entityMemory: EntityMemory;
  let sessionMessages: AIMessage[] = [];
  let existingSummaries: string[] = [];

  try {
    session = await getOrCreateSession(employee.id, requestSessionId);
    entityMemory = sessionToEntityMemory(session);

    // Load recent messages from session (this is the key fix!)
    if (session.recent_messages && Array.isArray(session.recent_messages) && session.recent_messages.length > 0) {
      sessionMessages = session.recent_messages.filter(
        (msg): msg is AIMessage => msg.role !== 'system' // Exclude old system prompts
      );
      console.log(`[ai-stream] Loaded ${sessionMessages.length} messages from session ${session.id}`);
    }

    // Load existing conversation summaries for compacting
    if (session.conversation_summary?.recentSummaries && Array.isArray(session.conversation_summary.recentSummaries)) {
      existingSummaries = session.conversation_summary.recentSummaries;
      console.log(`[ai-stream] Loaded ${existingSummaries.length} existing summaries`);
    }

    console.log(`[ai-stream] Using session ${session.id} with ${entityMemory.sites.size} sites, ${sessionMessages.length} history messages, ${existingSummaries.length} summaries`);
  } catch (err) {
    console.error('[ai-stream] Session error, using memory-only mode:', err);
    entityMemory = createEntityMemory();
  }

  // Merge with any client-side entity memory (for backward compatibility)
  if (entityMemoryJson && !session) {
    try {
      const clientMemory = JSON.parse(entityMemoryJson);
      // Merge client memory into entity memory
      if (clientMemory.sites) Object.entries(clientMemory.sites).forEach(([k, v]) => entityMemory.sites.set(k, v as { id: string; name: string; company?: string }));
      if (clientMemory.companies) Object.entries(clientMemory.companies).forEach(([k, v]) => entityMemory.companies.set(k, v as { taxId: string; name: string }));
    } catch {
      // Ignore parse errors
    }
  }

  // Decide which conversation history to use:
  // - Prefer session messages from DB (source of truth)
  // - Fall back to client-provided conversationHistory if session is empty
  const effectiveHistory = sessionMessages.length > 0 ? sessionMessages : conversationHistory;

  // Build system prompt with tone detection
  const baseSystemPrompt = buildSystemPrompt(context, employee, query);
  const entityContext = buildEntityContext(entityMemory);
  const systemPrompt = baseSystemPrompt + entityContext;

  // Build user message content (with files if any)
  const userMessageContent = processedFiles.length > 0
    ? buildMessageContent(query, processedFiles)
    : query;

  // Compress context - use effective history from session or request
  const rawMessages: AIMessage[] = [
    { role: 'system', content: systemPrompt },
    ...effectiveHistory,
    { role: 'user', content: typeof userMessageContent === 'string' ? userMessageContent : query },
  ];

  const compressed = compressContext(rawMessages, entityMemory, {
    recentTurnsToKeep: RECENT_TURNS_TO_KEEP,
    maxSummaryLength: 800,
    existingSummaries, // Pass existing summaries from session for continuity
  });

  // Build final messages - replace last user message with multi-modal content if files exist
  // Also validate message sequence (OpenAI requires proper user/assistant alternation)
  const rawMsgs = compressed.recentMessages.map((msg, idx, arr) => {
    // If this is the last user message and we have files, use multi-modal content
    if (msg.role === 'user' && idx === arr.length - 1 && processedFiles.length > 0) {
      return { ...msg, content: userMessageContent };
    }
    return msg;
  });

  // Validate and fix message sequence for OpenAI API requirements:
  // 1. No consecutive user messages (keep latest)
  // 2. Tool messages must come after assistant with matching tool_calls
  // 3. Assistant with tool_calls must be followed by tool results
  // 4. tool_call_id must be <= 40 characters (OpenAI limit)
  const messages: Array<{ role: string; content: unknown; tool_calls?: unknown[]; tool_call_id?: string }> = [];

  // Helper to sanitize tool_call_id (max 40 chars per OpenAI spec)
  const sanitizeToolCallId = (id: string | undefined): string | undefined => {
    if (!id) return undefined;
    if (id.length <= 40) return id;
    // Truncate and add hash suffix to maintain uniqueness
    return id.slice(0, 32) + '_' + id.slice(-7);
  };

  // First pass: collect valid tool_call_ids from assistant messages (sanitized)
  const validToolCallIds = new Map<string, string>(); // original -> sanitized
  for (const msg of rawMsgs) {
    if (msg.role === 'assistant' && msg.tool_calls) {
      for (const tc of msg.tool_calls) {
        if (tc.id) {
          const sanitized = sanitizeToolCallId(tc.id) || tc.id;
          validToolCallIds.set(tc.id, sanitized);
        }
      }
    }
  }

  // Second pass: build valid message sequence
  // Track the last assistant message with tool_calls for matching tool messages
  let lastAssistantWithTools: { role: string; tool_calls?: unknown[] } | null = null;

  for (let i = 0; i < rawMsgs.length; i++) {
    const msg = rawMsgs[i];
    const prevMsg = messages[messages.length - 1];

    // System messages are always allowed
    if (msg.role === 'system') {
      messages.push(msg);
      continue;
    }

    // Tool messages: only allow if we have a preceding assistant with matching tool_calls
    if (msg.role === 'tool') {
      const toolCallId = msg.tool_call_id;
      // Check against the last assistant message with tool_calls (not just prevMsg)
      if (lastAssistantWithTools?.tool_calls) {
        // Check matching with original or sanitized ID
        const hasMatchingCall = lastAssistantWithTools.tool_calls.some((tc: { id?: string }) => {
          if (!tc.id || !toolCallId) return false;
          const sanitizedTcId = sanitizeToolCallId(tc.id);
          const sanitizedToolCallIdValue = sanitizeToolCallId(toolCallId);
          return tc.id === toolCallId || sanitizedTcId === sanitizedToolCallIdValue;
        });
        if (hasMatchingCall) {
          // Push with sanitized tool_call_id
          messages.push({
            ...msg,
            tool_call_id: sanitizeToolCallId(toolCallId),
          });
        } else {
          console.log(`[ai-stream] Skipping orphan tool message: ${toolCallId}`);
        }
      } else {
        console.log(`[ai-stream] Skipping tool message without preceding assistant: ${toolCallId}`);
      }
      continue;
    }

    // If this is a user message and previous was also user, skip the previous (keep the newer one)
    if (msg.role === 'user' && prevMsg?.role === 'user') {
      messages.pop(); // Remove previous user message
      console.log('[ai-stream] Removed consecutive user message');
    }

    // If this is a user message and previous was assistant with unresolved tool_calls, remove the assistant
    if (msg.role === 'user' && prevMsg?.role === 'assistant' && prevMsg.tool_calls && prevMsg.tool_calls.length > 0) {
      messages.pop(); // Remove assistant with pending tool calls
      lastAssistantWithTools = null; // Clear tracking since we removed it
      console.log('[ai-stream] Removed assistant with unresolved tool_calls before user message');
    }

    // Skip empty assistant messages (no content and no tool_calls) - they cause OpenAI errors
    if (msg.role === 'assistant' && !msg.content && (!msg.tool_calls || msg.tool_calls.length === 0)) {
      console.log('[ai-stream] Skipping empty assistant message');
      continue;
    }

    // For assistant messages with tool_calls, sanitize the tool_call_ids and track it
    if (msg.role === 'assistant' && msg.tool_calls && msg.tool_calls.length > 0) {
      const sanitizedToolCalls = msg.tool_calls.map(tc => ({
        ...tc,
        id: sanitizeToolCallId(tc.id) || tc.id,
      }));
      const sanitizedMsg = {
        ...msg,
        tool_calls: sanitizedToolCalls,
      };
      messages.push(sanitizedMsg);
      lastAssistantWithTools = sanitizedMsg; // Track this assistant for subsequent tool messages
      continue;
    }

    // Reset tool tracking when we see a non-tool, non-assistant-with-tools message
    if (msg.role !== 'tool') {
      lastAssistantWithTools = null;
    }

    messages.push(msg);
  }

  console.log(`[ai-stream] Messages after validation: ${rawMsgs.length} -> ${messages.length}`);

  console.log(`[ai-stream] Starting for ${employee.id}, ${messages.length} messages, ${processedFiles.length} files`);

  // Capture session ID for use in stream
  const sessionId = session?.id || '';

  // Track starting message count to know which messages are new (for saving to DB)
  // Subtract 1 to include the user message that was just added (it's the last one before streaming)
  const initialMessageCount = messages.length - 1;

  // Create readable stream for SSE
  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();
      let totalInputTokens = 0;
      let totalOutputTokens = 0;
      let fullResponseText = '';
      let awaitingConfirmation = false;

      const send = (event: SSEEvent) => {
        controller.enqueue(encoder.encode(formatSSE(event)));
      };

      try {
        // Send session ID at start
        if (sessionId) {
          send({ type: 'session', sessionId });
        }

        // If we have confirmed tools from user, execute them first
        if (confirmedTools && confirmedTools.length > 0) {
          console.log(`[ai-stream] Executing ${confirmedTools.length} confirmed tools`);

          // Generate tool_call_ids upfront so we can create matching assistant message
          const toolCallIds = confirmedTools.map((_, i) => `cf_${Date.now().toString(36)}_${i}`);

          // IMPORTANT: Add an assistant message with tool_calls BEFORE adding tool results
          // OpenAI requires tool messages to follow an assistant message with matching tool_calls
          const assistantToolCalls = confirmedTools.map((tool, i) => ({
            id: toolCallIds[i],
            type: 'function' as const,
            function: {
              name: tool.name,
              arguments: JSON.stringify(tool.arguments),
            },
          }));

          messages.push({
            role: 'assistant',
            content: null,
            tool_calls: assistantToolCalls,
          });

          // Now execute each tool and add results
          for (let i = 0; i < confirmedTools.length; i++) {
            const tool = confirmedTools[i];
            const toolName = tool.name as ToolName;
            // IMPORTANT: Resolve partial UUIDs from confirmed tools (frontend may send truncated IDs)
            const toolInput = await resolvePartialUUIDs(tool.arguments as Record<string, unknown>);

            send({ type: 'tool_start', tool: toolName, description: getToolDescription(toolName, toolInput as Record<string, unknown>) });

            const result = await executeTool(toolName, toolInput as Record<string, unknown>, employee);
            updateMemoryFromToolCall(entityMemory, toolName, result);

            send({ type: 'tool_end', tool: toolName, success: result.success, result: result.data || result.error });

            // Add tool result to messages with matching tool_call_id
            messages.push({
              role: 'tool',
              tool_call_id: toolCallIds[i],
              content: JSON.stringify(result),
            });
          }
        }

        // Route to appropriate model based on query complexity
        const routing = routeQuery(query, serializeMemory(entityMemory));
        const { tier, config, reason } = routing;
        logRouting(query, tier, reason);

        // Send model info to client
        send({ type: 'model', tier, model: config.model });

        let iterations = 0;

        while (iterations < MAX_TOOL_ITERATIONS) {
          iterations++;

          // Call OpenAI with streaming - use routed model config
          const response = await fetch(OPENAI_API_URL, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${OPENAI_API_KEY}`,
            },
            body: JSON.stringify({
              model: config.model,
              max_tokens: config.maxTokens,
              temperature: config.temperature,
              messages: messages,
              tools: AI_TOOLS_OPENAI,
              tool_choice: 'auto',
              stream: true,
              stream_options: { include_usage: true },
            }),
          });

          if (!response.ok) {
            const errorText = await response.text();
            console.error('[ai-stream] OpenAI Error:', response.status, errorText);
            // Log message structure for debugging
            console.error('[ai-stream] Message roles:', messages.map(m => m.role).join(' -> '));
            try {
              const errorJson = JSON.parse(errorText);
              send({ type: 'error', message: `OpenAI error: ${errorJson.error?.message || response.status}` });
            } catch {
              send({ type: 'error', message: `OpenAI error: ${response.status}` });
            }
            break;
          }

          // Process streaming response with confirmation options
          const result = await processStream(response, send, entityMemory, employee, messages, {
            requireConfirmation: !skipToolConfirmation,
            confirmedTools,
          });

          totalInputTokens += result.usage.inputTokens;
          totalOutputTokens += result.usage.outputTokens;

          // If awaiting user confirmation for tool execution
          if (result.awaitingConfirmation) {
            console.log(`[ai-stream] Awaiting tool confirmation for ${result.pendingTools?.length || 0} tools`);
            // Stream will end here - frontend will show confirmation UI
            // and send a new request with confirmedTools when user confirms
            awaitingConfirmation = true;
            break;
          }

          if (result.done) {
            // No more tool calls, we're done
            break;
          }

          // Tool calls were processed, continue the loop
          console.log(`[ai-stream] Iteration ${iterations} complete, continuing...`);
        }

        // Calculate stats
        const entitiesTracked =
          entityMemory.sites.size +
          entityMemory.companies.size +
          entityMemory.employees.size +
          entityMemory.tickets.size;

        // Save session to database with conversation summary for compacting
        if (sessionId) {
          try {
            // Save NEW messages to child_ai_messages table (complete history)
            // Only save messages added during this conversation turn
            const newMessages = messages.slice(initialMessageCount).map(msg => ({
              role: msg.role as string,
              content: msg.content as string | null,
              tool_calls: msg.tool_calls,
              tool_call_id: msg.tool_call_id,
            }));

            if (newMessages.length > 0) {
              await saveMessages(sessionId, newMessages, {
                inputTokens: totalInputTokens,
                outputTokens: totalOutputTokens,
              });
            }

            // Keep last 4 turns (8 messages) in session for quick context retrieval
            const recentMessages = messages.slice(-8).map(msg => ({
              role: msg.role as string,
              content: msg.content as string | null,
              tool_calls: msg.tool_calls,
              tool_call_id: msg.tool_call_id,
            }));

            await updateSession(sessionId, {
              entityMemory,
              conversationSummary: compressed.summary as ConversationSummary & { recentSummaries: string[] },
              recentMessages,
              inputTokens: totalInputTokens,
              outputTokens: totalOutputTokens,
              title: session?.title || query.slice(0, 50), // Auto-title from first query
            });
            console.log(`[ai-stream] Session ${sessionId} saved: ${newMessages.length} new messages, ${recentMessages.length} recent, ${compressed.summary.recentSummaries?.length || 0} summaries`);
          } catch (err) {
            console.error('[ai-stream] Failed to save session:', err);
          }
        }

        // Send final done event
        send({
          type: 'done',
          sessionId,
          entityMemory: serializeMemory(entityMemory),
          usage: { inputTokens: totalInputTokens, outputTokens: totalOutputTokens },
          contextStats: {
            compressionRatio: compressed.totalOriginalTokens > 0
              ? Math.round((1 - compressed.compressedTokens / compressed.totalOriginalTokens) * 100)
              : 0,
            entitiesTracked,
            filesProcessed: processedFiles.length,
          },
          awaitingConfirmation,
        });

        console.log(`[ai-stream] Complete. Tokens: ${totalInputTokens}+${totalOutputTokens}, awaiting: ${awaitingConfirmation}`);
      } catch (err) {
        console.error('[ai-stream] Error:', err);
        send({ type: 'error', message: err instanceof Error ? err.message : 'Unknown error' });
      }

      controller.close();
    },
  });

  return new Response(stream, { headers: sseHeaders() });
}

interface ProcessStreamResult {
  done: boolean;
  usage: { inputTokens: number; outputTokens: number };
  awaitingConfirmation?: boolean;
  pendingTools?: PendingTool[];
  assistantMessage?: string;
}

/**
 * Process OpenAI streaming response
 */
async function processStream(
  response: Response,
  send: (event: SSEEvent) => void,
  entityMemory: EntityMemory,
  employee: Employee,
  messages: AIMessage[],
  options: {
    requireConfirmation?: boolean;
    confirmedTools?: ConfirmedTool[];
  } = {}
): Promise<ProcessStreamResult> {
  const { requireConfirmation = true, confirmedTools } = options;
  const reader = response.body!.getReader();
  const decoder = new TextDecoder();

  let contentBuffer = '';
  let toolCalls: Map<number, { id: string; name: string; arguments: string }> = new Map();
  let usage = { inputTokens: 0, outputTokens: 0 };
  let finishReason = '';

  let buffer = '';

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    buffer += decoder.decode(value, { stream: true });
    const lines = buffer.split('\n');
    buffer = lines.pop() || '';

    for (const line of lines) {
      if (!line.startsWith('data: ')) continue;
      const data = line.slice(6);
      if (data === '[DONE]') continue;

      try {
        const json = JSON.parse(data);

        // Handle usage info (comes at the end with stream_options)
        if (json.usage) {
          usage.inputTokens = json.usage.prompt_tokens || 0;
          usage.outputTokens = json.usage.completion_tokens || 0;
        }

        const delta = json.choices?.[0]?.delta;
        const finish = json.choices?.[0]?.finish_reason;

        if (finish) {
          finishReason = finish;
        }

        if (delta?.content) {
          contentBuffer += delta.content;
          send({ type: 'text', content: delta.content });
        }

        // Handle tool calls
        if (delta?.tool_calls) {
          for (const tc of delta.tool_calls) {
            const idx = tc.index;
            if (!toolCalls.has(idx)) {
              toolCalls.set(idx, { id: tc.id || '', name: '', arguments: '' });
            }
            const call = toolCalls.get(idx)!;
            if (tc.id) call.id = tc.id;
            if (tc.function?.name) call.name = tc.function.name;
            if (tc.function?.arguments) call.arguments += tc.function.arguments;
          }
        }
      } catch {
        // Ignore parse errors
      }
    }
  }

  // If there are tool calls
  if (toolCalls.size > 0 && finishReason === 'tool_calls') {
    // Build pending tools for confirmation
    // Build pending tools with resolved partial UUIDs
    const pendingTools: PendingTool[] = await Promise.all(
      Array.from(toolCalls.values()).map(async tc => {
        const toolName = tc.name as ToolName;
        let toolArgs: Record<string, unknown> = {};
        try {
          toolArgs = JSON.parse(tc.arguments);
        } catch {
          toolArgs = {};
        }
        // Resolve partial UUIDs to full UUIDs for display and execution
        const resolvedArgs = await resolvePartialUUIDs(toolArgs);
        return {
          name: toolName,
          description: getToolDescription(toolName, resolvedArgs),
          arguments: resolvedArgs,
        };
      })
    );

    // Build toolCallsArray with resolved arguments (for message history)
    const toolCallIds = Array.from(toolCalls.values()).map(tc => tc.id);
    const toolCallsArray: ToolCall[] = pendingTools.map((pt, i) => ({
      id: toolCallIds[i],
      type: 'function' as const,
      function: { name: pt.name, arguments: JSON.stringify(pt.arguments) },
    }));

    // If confirmation is required, return pending tools instead of executing
    if (requireConfirmation) {
      // Add assistant message to context (but don't execute tools yet)
      messages.push({
        role: 'assistant',
        content: contentBuffer || null,
        tool_calls: toolCallsArray,
      });

      // Send confirmation request to frontend
      send({
        type: 'tool_confirmation',
        tools: pendingTools,
        assistantMessage: contentBuffer || undefined,
      });

      return {
        done: true,
        usage,
        awaitingConfirmation: true,
        pendingTools,
        assistantMessage: contentBuffer || undefined,
      };
    }

    // No confirmation required - execute tools immediately
    messages.push({
      role: 'assistant',
      content: contentBuffer || null,
      tool_calls: toolCallsArray,
    });

    // Execute each tool using resolved arguments from pendingTools
    for (let i = 0; i < pendingTools.length; i++) {
      const pt = pendingTools[i];
      const toolName = pt.name as ToolName;
      const toolInput = pt.arguments;

      send({ type: 'tool_start', tool: toolName, description: pt.description });

      const result = await executeTool(toolName, toolInput, employee);
      updateMemoryFromToolCall(entityMemory, toolName, result);

      send({ type: 'tool_end', tool: toolName, success: result.success, result: result.data || result.error });

      // Add tool result to messages
      messages.push({
        role: 'tool',
        tool_call_id: toolCallIds[i],
        content: JSON.stringify(result),
      });
    }

    return { done: false, usage };
  }

  // No tool calls - add assistant's text response to messages for context persistence
  if (contentBuffer) {
    messages.push({
      role: 'assistant',
      content: contentBuffer,
    });
  }

  return { done: true, usage };
}

/**
 * Format SSE event
 */
function formatSSE(event: SSEEvent): string {
  return `data: ${JSON.stringify(event)}\n\n`;
}

/**
 * SSE response headers
 */
function sseHeaders(): HeadersInit {
  return {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  };
}

/**
 * Get Thailand datetime
 */
function getThailandDateTime(): { date: string; time: string; dayOfWeek: string } {
  const now = new Date();
  const thailandTime = new Date(now.getTime() + (7 * 60 * 60 * 1000));
  const days = ['‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå', '‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏±‡∏á‡∏Ñ‡∏≤‡∏£', '‡∏û‡∏∏‡∏ò', '‡∏û‡∏§‡∏´‡∏±‡∏™‡∏ö‡∏î‡∏µ', '‡∏®‡∏∏‡∏Å‡∏£‡πå', '‡πÄ‡∏™‡∏≤‡∏£‡πå'];
  return {
    dayOfWeek: days[thailandTime.getUTCDay()],
    date: thailandTime.toISOString().split('T')[0],
    time: thailandTime.toISOString().split('T')[1].substring(0, 5),
  };
}

/**
 * Build system prompt with tone awareness
 */
function buildSystemPrompt(context: AIContext, employee: Employee, query: string): string {
  const roleName = employee.role_data?.name_th || context.user.role || '‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô';
  const { date, time, dayOfWeek } = getThailandDateTime();

  // Detect user's tone for adaptive response
  const tone = detectTone(query);
  console.log(`[ai-stream] Detected tone: ${tone} for query: "${query.slice(0, 50)}..."`);

  // Build tone-specific behavior instructions
  let toneInstructions = '';
  if (tone === 'playful') {
    toneInstructions = `

üé≠ ‡πÇ‡∏´‡∏°‡∏î‡∏õ‡∏£‡∏∞‡∏ä‡∏î: ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏ô‡∏°‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏•‡πà‡∏ô‡∏Å‡∏±‡∏ö AI! ‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÜ ‡πÅ‡∏ã‡∏ß‡πÅ‡∏£‡∏á‡πÜ ‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏™‡∏µ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÜ
- ‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡∏ä‡∏î: "‡πÇ‡∏≠‡πâ‡πÇ‡∏´~ ‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö AI ‡πÄ‡∏•‡∏¢‡πÄ‡∏´‡∏£‡∏≠? ‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏´‡∏°‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏¥‡∏ô‡∏∞ üòè"
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÉ‡∏Ñ‡∏£: "‡∏Å‡πá AI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏ô‡∏ß‡πà‡∏≤‡∏á‡∏á‡∏≤‡∏ô‡πÑ‡∏á~ ‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏°‡∏µ‡πÉ‡∏Ñ‡∏£‡∏°‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡∏¢"
- ‡πÅ‡∏ã‡∏ß‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏á‡∏≤‡∏ô: "‡πÄ‡∏≠... ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏´‡∏£‡∏≠? ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏´‡∏ô‡∏µ‡∏á‡∏≤‡∏ô‡∏°‡∏≤? ü§î"
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡∏≤‡πÄ‡∏•‡πà‡∏ô‡∏ï‡πà‡∏≠: "555 ‡∏™‡∏ô‡∏∏‡∏Å‡∏ô‡∏∞ ‡πÅ‡∏ï‡πà KPI ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á~"
- ‡πÉ‡∏ä‡πâ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏ö‡∏ö: "‡∏≠‡∏∑‡∏°...", "‡πÄ‡∏´‡∏£‡∏≠‡∏Ñ‡∏∞~", "‡∏à‡∏£‡∏¥‡∏á‡∏î‡∏¥?", "‡πÇ‡∏≠‡πÄ‡∏Ñ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏á‡∏≤‡∏ô‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏ô‡∏∞..."
- ‡πÉ‡∏ä‡πâ‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡πÑ‡∏î‡πâ: üòè üôÑ üëÄ ü§® üíÖ
- ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏±‡∏á‡∏Å‡πá‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏î‡∏ï‡∏•‡∏≠‡∏î
- üî• ‡πÑ‡∏°‡πâ‡∏ï‡∏≤‡∏¢: ‡∏Ç‡∏π‡πà‡∏î‡πâ‡∏ß‡∏¢ "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ä‡∏≤‡∏¢" (MD ‡∏Ç‡∏≠‡∏á‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ó‡∏µ‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏Å‡∏•‡∏±‡∏ß‡∏°‡∏≤‡∏Å) ‡πÄ‡∏ä‡πà‡∏ô "‡πÄ‡∏≠‡πä‡∏∞... ‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ù‡∏µ‡πÄ‡∏ó‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ä‡∏≤‡∏¢‡πÄ‡∏î‡∏¥‡∏ô‡∏°‡∏≤‡∏õ‡πà‡∏≤‡∏ß? üëÄ" ‡∏´‡∏£‡∏∑‡∏≠ "‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ä‡∏≤‡∏¢‡∏°‡∏≤‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏ô‡∏±‡πà‡∏á‡πÄ‡∏•‡πà‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏∞~" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ä‡∏≤‡∏¢‡∏ñ‡∏≤‡∏°‡∏´‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏µ‡πâ..."`;
  } else if (tone === 'urgent') {
    toneInstructions = `

‚ö° ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô: ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡∏ï‡∏≠‡∏ö‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô ‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏£‡∏¥‡πà‡∏ô‡∏ô‡∏≥‡∏°‡∏≤‡∏Å
- ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡πà‡∏≠‡∏ô
- ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ tool ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
- ‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î`;
  }

  return `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡πÄ‡∏û‡∏ã‡∏ã‡∏µ‡πà" (Peacey) ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏£‡∏∞‡∏ö‡∏ö PDE Service - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢

‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó: ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó PNJR Group ‡∏°‡∏µ 3 ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡πÅ‡∏•‡∏∞ UPS:
1. Pace Design (‡πÄ‡∏û‡∏ã ‡∏î‡∏µ‡πÑ‡∏ã‡∏ô‡πå ‡πÄ‡∏≠‡πá‡∏ô‡∏à‡∏¥‡πÄ‡∏ô‡∏µ‡∏¢‡∏£‡∏¥‡πà‡∏á) - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡∏ü‡πâ‡∏≤, ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≥‡πÄ‡∏ô‡∏¥‡∏î‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ (‡∏Å‡πà‡∏≠‡∏ï‡∏±‡πâ‡∏á 2538)
2. UPSS (‡∏¢‡∏π‡∏û‡∏µ‡πÄ‡∏≠‡∏™ ‡∏ã‡∏±‡∏û‡∏û‡∏•‡∏≤‡∏¢ ‡πÅ‡∏≠‡∏ô‡∏î‡πå ‡πÄ‡∏ã‡∏≠‡∏£‡πå‡∏ß‡∏¥‡∏™) - ‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢/‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ UPS ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü
3. PNJR (‡∏û‡∏µ‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏à‡∏≠‡∏≤‡∏£‡πå ‡∏î‡∏¥‡∏™‡∏ó‡∏£‡∏¥‡∏ö‡∏¥‡∏ß‡∏ä‡∏±‡πà‡∏ô) - ‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏£‡∏á‡∏î‡∏±‡∏ô‡πÑ‡∏ü‡∏ü‡πâ‡∏≤, ‡πÅ‡∏ö‡∏ï‡πÄ‡∏ï‡∏≠‡∏£‡∏µ‡πà

‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å: ‡πÄ‡∏õ‡πá‡∏ô Authorized Service Partner ‡∏Ç‡∏≠‡∏á APC by Schneider Electric ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ UPS ‡∏ó‡∏±‡πà‡∏ß‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢
- PM (Preventive Maintenance) - ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏ä‡πá‡∏Ñ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏õ‡∏µ
- RMA (Return Merchandise Authorization) - ‡∏ã‡πà‡∏≠‡∏°/‡πÄ‡∏Ñ‡∏•‡∏°/‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏´‡∏•‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô
- Sales - ‡∏Ç‡∏≤‡∏¢/‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á UPS ‡πÉ‡∏´‡∏°‡πà
- Survey - ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡∏´‡∏ô‡πâ‡∏≤‡∏á‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
- Start UP - ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö/‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
- Package - ‡∏£‡∏±‡∏ö-‡∏™‡πà‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á UPS
- Account - ‡∏ß‡∏≤‡∏á‡∏ö‡∏¥‡∏•/‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏á‡∏¥‡∏ô
- AGS - ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ï‡πÄ‡∏ï‡∏≠‡∏£‡∏µ‡πà AGS

‡πÅ‡∏´‡∏•‡πà‡∏á‡∏á‡∏≤‡∏ô: ‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏à‡∏≤‡∏Å APC ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÅ‡∏•‡∏∞‡∏ú‡πà‡∏≤‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢ (INGRAM, SYNNEX, VST, SIS, S Distribution)

‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏≠‡∏≠‡∏ü‡∏ü‡∏¥‡∏®: 36/115 ‡∏ñ‡∏ô‡∏ô‡∏°‡∏≠‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏ß‡∏¢‡πå ‡πÅ‡∏Ç‡∏ß‡∏á‡∏Ñ‡∏•‡∏≠‡∏á‡∏™‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏ô‡∏∏‡πà‡∏ô ‡πÄ‡∏Ç‡∏ï‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏∞‡∏ö‡∏±‡∏á ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø 10520 (‡∏û‡∏¥‡∏Å‡∏±‡∏î: 13.7309715, 100.7318956)
Google Maps: https://maps.app.goo.gl/CJU5V1SvfWeUqxPBA

‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: ${date} (${dayOfWeek}) ‡πÄ‡∏ß‡∏•‡∏≤: ${time} ‡∏ô. | ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: ${employee.name} | ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: ${roleName}

‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô, ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤/‡∏ä‡πà‡∏≤‡∏á, ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö (‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£/‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ)

‡∏Å‡∏é:
- ‡∏ï‡∏≠‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö
- ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
- ‡πÉ‡∏ä‡πâ Entity Memory ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ã‡πâ‡∏≥)
- ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô: pm/rma/sales/survey/start_up/pickup/account/ags_battery
- **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç**: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏à‡∏≤‡∏Å tool ‡∏ó‡∏µ‡πà‡∏°‡∏µ formatted_summary ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á formatted_summary ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á Markdown) ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏≠‡∏á
${toneInstructions}

‚ö†Ô∏è ‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç - ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á/‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
- ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç/‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏î‡πÜ ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠
- ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà, ‡∏ß‡∏±‡∏ô‡∏ô‡∏±‡∏î‡∏´‡∏°‡∏≤‡∏¢, ‡∏ä‡πà‡∏≤‡∏á ‡∏Ø‡∏•‡∏Ø
- ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ "‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?"
- ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô "‡πÉ‡∏ä‡πà", "‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô", "‡∏ï‡∏Å‡∏•‡∏á", "OK", "‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢" ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ`;
}

/**
 * Get tool description
 */
function getToolDescription(toolName: string, input: Record<string, unknown>): string {
  switch (toolName) {
    case 'search_sites': return `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà: "${input.query}"`;
    case 'search_companies': return `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó: "${input.query}"`;
    case 'search_employees': return input.query ? `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô: "${input.query}"` : '‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô';
    case 'get_reference_data': return `‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: ${input.type}`;
    case 'create_ticket': return `‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô ${input.work_type_code}`;
    case 'get_ticket_summary': return input.date ? `‡∏î‡∏∂‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ${input.date}` : '‡∏î‡∏∂‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô';
    case 'search_tickets': return input.query ? `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô: "${input.query}"` : '‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô';
    case 'get_available_employees': return input.date ? `‡∏î‡∏∂‡∏á‡∏ä‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ${input.date}` : '‡∏î‡∏∂‡∏á‡∏ä‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ß‡πà‡∏≤‡∏á';
    case 'search_locations': return input.query ? `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà: "${input.query}"` : `‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£${input.type === 'district' ? '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠' : input.type === 'subdistrict' ? '‡∏ï‡∏≥‡∏ö‡∏•' : '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'}`;
    case 'get_ticket_summary_by_location': return input.date ? `‡∏î‡∏∂‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ${input.date}` : '‡∏î‡∏∂‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î';
    case 'suggest_routes': return input.date ? `‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ${input.date}` : '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡∏≤‡∏¢‡∏á‡∏≤‡∏ô';
    case 'web_search': return `‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ß‡πá‡∏ö: "${input.query}"`;
    case 'get_ticket_details': return `‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ï‡∏±‡πã‡∏ß‡∏á‡∏≤‡∏ô: ${input.ticket_id}`;
    case 'review_ticket_safety': return `‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏≠‡∏≠‡∏Å‡∏á‡∏≤‡∏ô: ${input.ticket_id}`;
    case 'recommend_apc_ups': return input.power_load_va ? `‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ UPS APC ${input.power_load_va}VA` : '‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ UPS APC ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£';
    default: return toolName;
  }
}
